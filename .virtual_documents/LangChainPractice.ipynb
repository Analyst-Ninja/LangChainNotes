


from dotenv import load_dotenv


load_dotenv()


from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate
from langchain_community.llms import Ollama


chat = Ollama(model='llama3')


response_schemas = [
    ResponseSchema(name='bad_string', description='This is a poorly formatted user input string'),
    ResponseSchema(name='good_string', description='This is your response, a reformatted response'),
]

output_parser = StructuredOutputParser.from_response_schemas(response_schemas)


format_instructions = output_parser.get_format_instructions()
print(format_instructions)


template = """
You are will be given a poorly formatted string from a user.
Reformat it and make sure all the words are spelled correctly

{format_instructions}

get_ipython().run_line_magic("USER", " INPUT:")
{user_input}

YOUR RESPONSE:
"""

prompt = PromptTemplate(
    input_variables=['user_input'],
    partial_variables={"format_instructions" : format_instructions},
    template=template
)

promptValue = prompt.format(user_input="Welcome to Californiya!")
print(promptValue)


llm_output = chat.invoke(promptValue)


print(llm_output)


parsed_output = output_parser.parse(llm_output)
print(parsed_output)





from langchain.text_splitter import RecursiveCharacterTextSplitter

with open('hp.txt', 'r') as f:
    data = f.read()

print(f'Length of the data : {len([data])}')


text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 1000,
    chunk_overlap = 100
) 

texts = text_splitter.create_documents([data]) 


print(f'You have {len(texts)} documents.')





from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
# from langchain.embeddings import OllamaEmbeddings # Depricated 
from langchain_ollama.embeddings import OllamaEmbeddings

loader = TextLoader('hp.txt')
documents = loader.load()


text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 1000,
    chunk_overlap = 100
)

texts = text_splitter.split_documents(documents)

embeddings = OllamaEmbeddings(model='llama3')

db = FAISS.from_documents(texts[:1], embeddings)


retriever = db.as_retriever()


docs = retriever.get_relevant_documents('What is the place name here')


docs, len(docs)


l = "\n".join([x.page_content for x in docs])
print(l)





from langchain.memory import ChatMessageHistory
from langchain_community.llms import Ollama

chat = Ollama(model='llama3')

history = ChatMessageHistory()

history.add_ai_message('Hi')

history.add_user_message('What is a capital for India?')


history.messages


ai_response = chat.invoke(history.messages)
ai_response


history.add_ai_message(ai_response)


history.messages


while True:
    history.add_user_message(input('User Prompt: '))
    ai_response = chat.invoke(history.messages)
    history.add_ai_message(ai)
    print(f"AI Response: {ai_response}")



